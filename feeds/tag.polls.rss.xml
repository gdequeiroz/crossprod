<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Crossprod</title><link>http://nacnudus.github.io/crossprod/</link><description>R, data, and frustration</description><atom:link href="http://nacnudus.github.io/crossprod/feeds/tag.polls.rss.xml" rel="self"></atom:link><lastBuildDate>Tue, 28 Jun 2016 00:00:00 +1200</lastBuildDate><item><title>Hacking the Data Science Radar with DataÂ Science</title><link>http://nacnudus.github.io/crossprod/hacking-the-data-science-radar-with-data-science</link><description>&lt;p&gt;This post reverse-engineers the Mango Solutions &lt;a href="https://www.mango-solutions.com/radar/"&gt;Data Science
Radar&lt;/a&gt;&amp;nbsp;using&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Programming&amp;nbsp;(R)&lt;/li&gt;
&lt;li&gt;Visualisation&amp;nbsp;(ggplot2) &lt;/li&gt;
&lt;li&gt;Data wrangling&amp;nbsp;(dpylr/tidyr/etc.)&lt;/li&gt;
&lt;li&gt;Modelling&amp;nbsp;(lm)&lt;/li&gt;
&lt;li&gt;Technology (embedded V8&amp;nbsp;javascript)&lt;/li&gt;
&lt;li&gt;Communication&amp;nbsp;(blog)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Why hack?  Because getting at the innards also&amp;nbsp;reveals&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What a good score is in each&amp;nbsp;category&lt;/li&gt;
&lt;li&gt;Which statements are most&amp;nbsp;important&lt;/li&gt;
&lt;li&gt;Whether scores are comparable across&amp;nbsp;people&lt;/li&gt;
&lt;li&gt;Whether you should strongly agree with the statement &amp;#8220;On average, I spend at
  least 25% of my time manipulating data into analysis-ready&amp;nbsp;formats&amp;#8221;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="the-radar"&gt;The&amp;nbsp;radar&lt;/h2&gt;
&lt;p&gt;Based on Likert-style responses to 24 provocative statements, the Data
Science Radar visualises your skills along six axes, the &amp;#8220;core attributes of a
contemporary &amp;#8216;Data Scientist&amp;#8217;.&amp;#8221; It looks like&amp;nbsp;this.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Mango Solutions Data Science Radar" src="figure/radar.png" /&gt;&lt;/p&gt;
&lt;h2 id="first-attempt-multivariate-multiple-regression"&gt;First attempt: Multivariate multiple&amp;nbsp;regression&lt;/h2&gt;
&lt;p&gt;How can we score better?  Hacking the url would be
&lt;a href="https://www.mango-solutions.com/radar/?fs=true&amp;amp;r=7.0,7.0,7.0,7.0,7.0,7.0"&gt;cheating&lt;/a&gt;,
so instead, let&amp;#8217;s use science: hypothesise -&amp;gt; test -&amp;gt; improve.  Here are some
initial&amp;nbsp;guesses.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Each of the 24 statements relates to exactly one attribute, i.e. four
  statements per&amp;nbsp;attribute.&lt;/li&gt;
&lt;li&gt;The Likert values (strongly agree, agree, somewhat agree, etc.) are coded from
  1 to 7 (since there are seven points on each&amp;nbsp;axis).&lt;/li&gt;
&lt;li&gt;There is a linear relationship between the coded agreement with the
  statements, and the&amp;nbsp;attributes.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So something&amp;nbsp;like
&lt;/p&gt;
&lt;div class="math"&gt;$$\text{score}_{\text{attribute}} = \frac{1}{4} \sum_{i = 1}^{4} \text{answer}_i$$&lt;/div&gt;
&lt;p&gt;
where &lt;span class="math"&gt;\(\text{answer}_i = 1, 2, \cdots, 7\)&lt;/span&gt; by encoding &amp;#8220;Strongly disagree&amp;#8221; as
1, up to &amp;#8220;Strongly agree&amp;#8221; as 7, including only four relevant answers per
attribute.  The best-possible set of answers would score 7 on every axis, and
the worst set would score&amp;nbsp;1.&lt;/p&gt;
&lt;p&gt;If the hypotheses are correct, then all we need to do to prove them is to record
24 sets of random answers, the resulting scores, and fit a multivariate
linear model.  We&amp;#8217;d expect each score (outcome variable) to have four non-zero
coefficients (out of the 24 input variables).  Let&amp;#8217;s try&amp;nbsp;it.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c1"&gt;# The first two aren&amp;#39;t random, but they&amp;#39;re still linearly independent of the&lt;/span&gt;
&lt;span class="c1"&gt;# others, which is what matters.&lt;/span&gt;
random_data &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; read_csv&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;./data/radar-random.csv&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
lm1 &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; lm&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;cbind&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;Communicator&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="sb"&gt;`Data Wrangler`&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; Modeller&lt;span class="p"&gt;,&lt;/span&gt; 
                Programmer&lt;span class="p"&gt;,&lt;/span&gt; Technologist&lt;span class="p"&gt;,&lt;/span&gt; Visualiser&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;~&lt;/span&gt; &lt;span class="m"&gt;.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; data &lt;span class="o"&gt;=&lt;/span&gt; random_data&lt;span class="p"&gt;)&lt;/span&gt;
lm1
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;## 
## Call:
## lm(formula = cbind(Communicator, `Data Wrangler`, Modeller, Programmer, 
##     Technologist, Visualiser) ~ ., data = random_data)
## 
## Coefficients:
##              Communicator  Data Wrangler  Modeller    Programmer  Technologist  Visualiser
## (Intercept)   2.060e+00     2.422e+00      3.247e+00   6.658e-01  -1.331e+00     1.456e+00
## q01           1.997e-01    -2.507e-02      2.602e-01  -1.103e-01  -5.866e-02    -7.103e-02
## q02          -2.571e-01     2.729e-02     -4.514e-01   2.090e-01   1.554e-01     1.281e-01
## q03           3.087e-01     1.744e-02     -3.471e-01  -1.303e-03   5.611e-02     1.978e-01
## q04           4.356e-01     8.534e-04     -8.676e-03  -2.346e-02  -7.130e-02    -4.193e-02
## q05          -2.524e-01     2.267e-01      8.732e-01  -1.559e-01  -1.907e-01    -3.885e-01
## q06          -1.948e-01     1.545e-01      7.016e-01  -7.626e-02  -1.271e-01    -3.897e-01
## q07          -7.925e-03     2.075e-01      4.423e-01  -1.089e-01  -2.015e-01    -2.247e-01
## q08           8.902e-02    -4.810e-01     -1.246e-02   8.111e-02  -5.556e-02    -4.572e-02
## q09           1.901e-01     5.174e-02     -5.260e-01  -9.428e-02   5.506e-02     2.620e-01
## q10           9.750e-02    -1.248e-02     -2.365e-01   3.181e-02   1.557e-01     3.267e-01
## q11          -2.099e-01    -5.220e-02      2.943e-01   2.032e-01   6.801e-02    -1.775e-01
## q12          -1.000e-01     1.813e-15      7.000e-01  -1.333e-01   9.653e-16    -1.000e-01
## q13           5.164e-02     2.647e-02     -3.386e-01   2.881e-01  -4.010e-03     1.428e-01
## q14           1.211e-01    -8.162e-02     -3.835e-02  -2.508e-01  -4.963e-02     7.972e-02
## q15           4.971e-03     5.740e-02     -2.581e-01   3.729e-01   7.939e-02     1.018e-01
## q16           2.450e-01    -6.448e-02      6.447e-02   1.757e-01  -2.060e-01     7.158e-03
## q17          -2.310e-01     8.405e-02     -3.947e-02   1.424e-01   3.434e-01    -8.871e-02
## q18           4.003e-02    -4.045e-02      2.264e-02  -9.453e-02   2.958e-01    -2.477e-02
## q19           5.952e-02     5.815e-02     -6.029e-01   6.573e-02   5.393e-01     2.828e-01
## q20          -8.766e-02     2.262e-01     -6.807e-01   1.403e-01   5.257e-01     3.440e-01
## q21           1.903e-01    -3.190e-02     -6.312e-01   1.331e-01   5.689e-02     4.847e-01
## q22          -1.334e-01     5.980e-02      1.251e-01   8.396e-02   7.175e-02    -4.788e-01
## q23          -5.700e-02    -1.563e-01      5.947e-01  -1.535e-01  -1.894e-01    -6.388e-02
## q24          -1.419e-01     4.202e-02      2.188e-01   2.128e-02  -4.087e-02     2.361e-01
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Hopeless!  At least one of the assumptions must be wrong, but which one?  This
time, let&amp;#8217;s use our brains instead of stats, and do a&amp;nbsp;visualisation.  &lt;/p&gt;
&lt;h2 id="visualisation-brain-not-brawn"&gt;Visualisation: Brain not&amp;nbsp;brawn&lt;/h2&gt;
&lt;p&gt;Since patterns are hard to find among random responses, I answered 24 more
surveys systematically, answering &amp;#8220;Strongly disagree&amp;#8221; to one statement, and
&amp;#8220;Strongly agree&amp;#8221; to all the others, until all 24 statements had been strongly
disagreed with. One time, I answered one with &amp;#8220;Strongly agree&amp;#8221; to every
statement, plotting the resulting scores at 0 on the&amp;nbsp;x-axis.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://nacnudus.github.io/crossprod/figure/radar-systematic-1.svg" title="plot of chunk radar-systematic" alt="plot of chunk radar-systematic" width="960px" height="540px" /&gt;&lt;/p&gt;
&lt;p&gt;Let&amp;#8217;s break this&amp;nbsp;down.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The maximum score appears to be 7, which &amp;#8216;Technologist&amp;#8217; got most of the time.
  If you&amp;#8217;re a technologist, you should agree with&amp;nbsp;everything.&lt;/li&gt;
&lt;li&gt;Disagreement with any of the statements drastically affects the score of
  exactly one attribute, with minor effects on some/all of the&amp;nbsp;others.&lt;/li&gt;
&lt;li&gt;Sometimes disagreement affects attributes for the better (e.g. 2 improves
  &amp;#8216;Communicator&amp;#8217;).  Sometimes it&amp;#8217;s really damaging (e.g. 17&amp;#8212;20 ruins&amp;nbsp;&amp;#8216;Technologist&amp;#8217;).&lt;/li&gt;
&lt;li&gt;There are no ties between attributes.  This is a massive&amp;nbsp;clue.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It&amp;#8217;s now easy from this graph to work out the perfect survey responses.  For
example, we could max-out &amp;#8216;Communicator&amp;#8217; by agreeing with statements 1, 3, and
4, but disagreeing with statement 2 &amp;#8212; which caused a peak in the previous&amp;nbsp;graph.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://nacnudus.github.io/crossprod/figure/radar-perfect-1.svg" title="plot of chunk radar-perfect" alt="plot of chunk radar-perfect" width="960px" height="540px" /&gt;&lt;/p&gt;
&lt;p&gt;This is much&amp;nbsp;clearer.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Each attribute relates to four&amp;nbsp;statements.&lt;/li&gt;
&lt;li&gt;Not only that, but related statements are grouped together (okay, that&amp;#8217;s
  guessable from just doing the&amp;nbsp;survey).&lt;/li&gt;
&lt;li&gt;Not every statement is equally weighted (the trough depths vary within&amp;nbsp;groups).&lt;/li&gt;
&lt;li&gt;Even the statement weighting system varies between questions (the range of
  trough depths varies between&amp;nbsp;groups).&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="penalties"&gt;Penalties&lt;/h2&gt;
&lt;p&gt;Crucially, it&amp;#8217;s now obvious from the parallel movements between 0 and 1, 4 and
5, and 8 and 9, that attributes are penalized by their rank.  When statement 1
is strongly disagreed with, &amp;#8216;Communicator&amp;#8217; has the bottom score, and the others
are spread between 7 and five.  But when statement 1 is strongly agreed with
(position 0 on the x-axis), &amp;#8216;Communicator&amp;#8217; takes the lead with a score of 7, and
the scores of all the others are bumped down a step.  This strongly suggests
that the scores are penalised by some function of the&amp;nbsp;rank.&lt;/p&gt;
&lt;p&gt;Think of it this way: if they&amp;#8217;re all equal-first-place, then rank them
arbitrarily (zero-based rank, 0 to 5), and then penalise them by, say,
subtracting their rank from their score.  So say &amp;#8216;Communicator&amp;#8217; is arbitrarily
ranked zero-th among equals (i.e. first place), then &amp;#8216;Communicator&amp;#8217; still scores
7, But &amp;#8216;Modeller&amp;#8217;, ranked 1 (second place), loses 1 point, and &amp;#8216;Programmer&amp;#8217;,
ranked 2 (third place) loses 2 points.  This penalisation process guarantees
against any ties, but it also obfuscates any straightforward relationship
between survey response and pre-penalty&amp;nbsp;scores.&lt;/p&gt;
&lt;p&gt;Here&amp;#8217;s the penalty function in action.  I answered every statement &amp;#8216;correctly&amp;#8217;,
except for statement 1, which I answered at every level from &amp;#8220;Strongly disagree&amp;#8221;
to &amp;#8220;Strongly agree&amp;#8221;.  Note the change of axis&amp;nbsp;variables.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://nacnudus.github.io/crossprod/figure/radar-diff-1.svg" title="plot of chunk radar-diff" alt="plot of chunk radar-diff" width="960px" height="540px" /&gt;&lt;/p&gt;
&lt;p&gt;As my answers go from &amp;#8220;Strongly disagree&amp;#8221; up to &amp;#8220;Agree&amp;#8221; (0 to 6 on the x-axis),
the score of &amp;#8216;Communicator&amp;#8217; gradually increases, as we&amp;#8217;d expect.  But in the
final step, &amp;#8220;Strongly agree&amp;#8221;, there&amp;#8217;s a jump.  That&amp;#8217;s because &amp;#8216;Communicator&amp;#8217; is
now ranked (abitrarily) in first place, so no penalty is applied, and it gets
the full 7 points.  At the same time, the other attributes are bumped&amp;nbsp;down.&lt;/p&gt;
&lt;h2 id="hunt-the-function"&gt;Hunt the&amp;nbsp;function&lt;/h2&gt;
&lt;p&gt;We need to remove these penalties before we can investigate the
statement/response weightings, but we don&amp;#8217;t yet know what exactly the penalty
function is, besides being some function of the rank.  Using the perfect
answers, though (at 6 on the x-axis above), we can get clues to narrow down the
options.  Since we know that the original pre-penalty score of every attribute
ought to have been 7, then by subtracting their final scores from 7, we reveal
the size of the&amp;nbsp;penalty.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kp"&gt;sort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="kp"&gt;unlist&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;perfect_data&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;-1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="m"&gt;-24&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;       &lt;span class="c1"&gt;# absolute penalty&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;##  Communicator      Modeller    Programmer  Technologist    Visualiser Data Wrangler 
##           0.0           0.4           0.7           1.0           1.4           1.8
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So penalties can be as large as 1.8.  That would be a problem for poor-ranking
pre-penalty scores below 1.8, which would be pushed below zero.  To guarantee
positive final scores, the penalty function must scale with the pre-penalty
score, i.e. the pre-penalty score must be a coefficient in the function.  That
restricts us to a couple of basic designs for each attribute&amp;#8217;s&amp;nbsp;score.&lt;/p&gt;
&lt;p&gt;Either:&lt;/p&gt;
&lt;div class="math"&gt;$$\text{final score} = \text{pre-penalty} - (\text{pre-penalty} \times \text{factor} \times \text{rank})$$&lt;/div&gt;
&lt;p&gt;
where &lt;span class="math"&gt;\(0 \leq \text{factor} &amp;lt; 1/5\)&lt;/span&gt; (for&amp;nbsp;positivity).&lt;/p&gt;
&lt;p&gt;Or:&lt;/p&gt;
&lt;div class="math"&gt;$$\text{final score} = \text{factor} \times \frac{\text{pre-penalty}}{\text{rank}}$$&lt;/div&gt;
&lt;p&gt;
where &lt;span class="math"&gt;\(0 \leq \text{factor} &amp;lt; 1\)&lt;/span&gt; (to ensure a penalty when &lt;span class="math"&gt;\(\text{rank} = 1\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;There is a telling difference between these functions.  The first is a straight
line, essentially &lt;span class="math"&gt;\(y = mx + c\)&lt;/span&gt;, so that, given equal pre-penalty scores, the
differences between final scores are equal.  The second is a curve, essentially
&lt;span class="math"&gt;\(y = m/x\)&lt;/span&gt;, so that, even given equal pre-penalty scores, the gap between
poorly-ranked scores is wider than between the top&amp;nbsp;scores.&lt;/p&gt;
&lt;p&gt;Since we have a handy set of equal pre-penalty scores, we can eliminate one of
the functions by seeing whether the difference in penalties between ranks is, in
fact,&amp;nbsp;constant.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kp"&gt;diff&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;sort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="kp"&gt;unlist&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;perfect_data&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;-1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="m"&gt;-24&lt;/span&gt;&lt;span class="p"&gt;])))&lt;/span&gt; &lt;span class="c1"&gt;# difference in penalties between ranks&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;##      Modeller    Programmer  Technologist    Visualiser Data Wrangler 
##           0.4           0.3           0.3           0.4           0.4
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;It&amp;#8217;s constant enough for me, so I choose the first&amp;nbsp;model.&lt;/p&gt;
&lt;p&gt;We can also check that penalties do, indeed, scale with the pre-penalty scores,
by producing a set of &lt;a href="https://www.mango-solutions.com/radar/?fs=true&amp;amp;r=1.0,0.9,0.9,0.8,0.8,0.7"&gt;worst-possible
answers&lt;/a&gt;.
Pay attention: these are the scores to&amp;nbsp;beat.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;## Source: local data frame [6 x 2]
## 
##       attribute score
##           &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt;
## 1  Communicator   1.0
## 2      Modeller   0.9
## 3    Programmer   0.9
## 4  Technologist   0.8
## 5    Visualiser   0.8
## 6 Data Wrangler   0.7
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="Mango Solutions Data Science Radar: worst score" src="figure/radar-worst.png" /&gt;&lt;/p&gt;
&lt;p&gt;Not only does this prove the scaling of penalties by pre-penalty score, but it
also justifies the coding of &amp;#8216;agreement&amp;#8217; between 1 and 7, rather than, say, 0
and 6, since we now have a clear minimum pre-penalty score of 1, as well as a
maximum of 7 from the set of perfect&amp;nbsp;answers.&lt;/p&gt;
&lt;p&gt;If you look carefully, this set of worst-possible scores also hints at the value
of the penalty factor.  Since the pre-penalty score is 1, and the difference
between penalties is constant by design, and the difference between &lt;em&gt;these&lt;/em&gt;
penalties alternates between 0.1 and 0.0, I &lt;em&gt;strongly&lt;/em&gt; suspect a factor of 0.5
and a rounding system that alternates between odds and&amp;nbsp;evens.&lt;/p&gt;
&lt;h2 id="modelling-success"&gt;Modelling&amp;nbsp;success&lt;/h2&gt;
&lt;p&gt;But we can nail this down with a linear model, using the two sets of data where
we already know the pre-penalty scores, i.e. the best- and worst-possible
scores, as well as the ranks, so we can estimate the penalty&amp;nbsp;factor.  &lt;/p&gt;
&lt;p&gt;A reminder of the&amp;nbsp;model:&lt;/p&gt;
&lt;div class="math"&gt;$$\text{final score} = \text{pre-penalty} - (\text{pre-penalty} \times \text{factor} \times \text{rank})$$&lt;/div&gt;
&lt;p&gt;
where &lt;span class="math"&gt;\(0 \leq \text{factor} &amp;lt; 1/5\)&lt;/span&gt; (for&amp;nbsp;positivity).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;worst&lt;span class="o"&gt;$&lt;/span&gt;rank &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="m"&gt;5&lt;/span&gt;
worst&lt;span class="o"&gt;$&lt;/span&gt;prepenalty &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;
best &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; 
  frame_data&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;~&lt;/span&gt;attribute&lt;span class="p"&gt;,&lt;/span&gt;     &lt;span class="o"&gt;~&lt;/span&gt;&lt;span class="kp"&gt;rank&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;~&lt;/span&gt;score&lt;span class="p"&gt;,&lt;/span&gt;
             &lt;span class="s"&gt;&amp;quot;Communicator&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;     &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;    &lt;span class="m"&gt;7.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
             &lt;span class="s"&gt;&amp;quot;Modeller&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;         &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;    &lt;span class="m"&gt;6.6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
             &lt;span class="s"&gt;&amp;quot;Programmer&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;       &lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;    &lt;span class="m"&gt;6.3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
             &lt;span class="s"&gt;&amp;quot;Technologist&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;     &lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;    &lt;span class="m"&gt;6.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
             &lt;span class="s"&gt;&amp;quot;Visualiser&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;       &lt;span class="m"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;    &lt;span class="m"&gt;5.6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
             &lt;span class="s"&gt;&amp;quot;Data Wrangler&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;    &lt;span class="m"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;    &lt;span class="m"&gt;5.2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
best&lt;span class="o"&gt;$&lt;/span&gt;prepenalty &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="m"&gt;7&lt;/span&gt;

lm&lt;span class="p"&gt;(&lt;/span&gt;score &lt;span class="o"&gt;~&lt;/span&gt; prepenalty &lt;span class="o"&gt;+&lt;/span&gt; prepenalty&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="kp"&gt;rank&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; data &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kp"&gt;rbind&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;best&lt;span class="p"&gt;,&lt;/span&gt; worst&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;## 
## Call:
## lm(formula = score ~ prepenalty + prepenalty:rank, data = rbind(best, 
##     worst))
## 
## Coefficients:
##     (Intercept)       prepenalty  prepenalty:rank  
##        -0.02778          1.00349         -0.05029
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;That&amp;#8217;ll do!  The coefficient on the pre-penalty score is 1, as in our
model, and the coefficient on the pre-penalty&amp;#8212;rank interaction is -0.05, a nice
round number such as a model-builder might choose (and the right&amp;nbsp;sign).&lt;/p&gt;
&lt;h2 id="weighting-game"&gt;Weighting&amp;nbsp;game&lt;/h2&gt;
&lt;p&gt;We&amp;#8217;re on the home straight.  Now that we understand the penalty system, we can
go beneath its obfuscations and sort out the statement weights.  Here, I invert
the penalty function, and apply it to an earlier set of answers that you&amp;#8217;ll
recognise in the&amp;nbsp;graph.&lt;/p&gt;
&lt;div class="math"&gt;$$\text{pre-penalty} = \frac{\text{final score}}{1 - (\text{factor} \times \text{rank})}$$&lt;/div&gt;
&lt;p&gt;&lt;img src="http://nacnudus.github.io/crossprod/figure/radar-penalty-inverse-1.svg" title="plot of chunk radar-penalty-inverse" alt="plot of chunk radar-penalty-inverse" width="960px" height="540px" /&gt;&lt;/p&gt;
&lt;p&gt;It does the soul good to see the pre-penalty attribute scores restored (bar&amp;nbsp;rounding).&lt;/p&gt;
&lt;p&gt;The weight of each statement equals the amount of damage that it can do to the
relevant attribute&amp;#8217;s score, divided by the total damage done by the other
relevant&amp;nbsp;statements.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;##             type Score damage weight
## 1   Communicator  5.73   1.27   0.20
## 2   Communicator  5.73   1.27   0.20
## 3   Communicator  5.73   1.27   0.20
## 4   Communicator  4.53   2.47   0.39
## 5  Data Wrangler  5.47   1.53   0.23
## 6  Data Wrangler  5.47   1.53   0.23
## 7  Data Wrangler  5.47   1.53   0.23
## 8  Data Wrangler  5.07   1.93   0.30
## 9       Modeller  5.73   1.27   0.20
## 10      Modeller  5.73   1.27   0.20
## 11      Modeller  5.73   1.27   0.20
## 12      Modeller  4.53   2.47   0.39
## 13    Programmer  5.73   1.27   0.21
## 14    Programmer  5.73   1.27   0.21
## 15    Programmer  5.20   1.80   0.29
## 16    Programmer  5.20   1.80   0.29
## 17  Technologist  5.73   1.27   0.21
## 18  Technologist  5.20   1.80   0.29
## 19  Technologist  5.20   1.80   0.29
## 20  Technologist  5.73   1.27   0.21
## 21    Visualiser  5.73   1.27   0.21
## 22    Visualiser  5.20   1.80   0.29
## 23    Visualiser  5.73   1.27   0.21
## 24    Visualiser  5.20   1.80   0.29
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Being nice fractions, the three systems make perfect sense (allowing yet again for minor
rounding): &lt;span class="math"&gt;\((\frac{1}{5}\)&lt;/span&gt;, &lt;span class="math"&gt;\(\frac{1}{5}\)&lt;/span&gt;, &lt;span class="math"&gt;\(\frac{1}{5}\)&lt;/span&gt;, &lt;span class="math"&gt;\(\frac{2}{5})\)&lt;/span&gt;, &lt;span class="math"&gt;\((\frac{7}{30}\)&lt;/span&gt;, &lt;span class="math"&gt;\(\frac{7}{30}\)&lt;/span&gt;, &lt;span class="math"&gt;\(\frac{7}{30}\)&lt;/span&gt;, &lt;span class="math"&gt;\(\frac{9}{30})\)&lt;/span&gt;, and &lt;span class="math"&gt;\((\frac{2}{10}\)&lt;/span&gt;, &lt;span class="math"&gt;\(\frac{2}{10}\)&lt;/span&gt;, &lt;span class="math"&gt;\(\frac{3}{10}\)&lt;/span&gt;, &lt;span class="math"&gt;\(\frac{3}{10})\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;And don&amp;#8217;t forget to re-write the model to account for the&amp;nbsp;weights.&lt;/p&gt;
&lt;div class="math"&gt;$$\text{score}_{\text{attribute}} = \sum_{i = 1}^{4} \text{answer}_i \times
\text{weight}_i$$&lt;/div&gt;
&lt;p&gt; where &lt;span class="math"&gt;\(\text{weight}_i\)&lt;/span&gt; is taken from&amp;nbsp;above.&lt;/p&gt;
&lt;h2 id="implementation-and-simulation"&gt;Implementation and&amp;nbsp;simulation&lt;/h2&gt;
&lt;p&gt;At last, we can implement the whole thing in R, run it on thousands of random
answer-sets, and explore the distributions.  Well, almost &amp;#8212; it turns out that R
and JavaScript handle rounding and floating-point arithmetic differently, so I
had to use the &lt;a href="https://github.com/jeroenooms/V8"&gt;V8&lt;/a&gt; package to implement the
rounding steps in JavaScript, as the website does.  I give more details in a
&lt;a href="http://nacnudus.github.io/crossprod/r-rounding-is-weird-try-javascript"&gt;previous post&lt;/a&gt;.  At least I got to display some
&amp;#8216;Technologist&amp;#8217;&amp;nbsp;skills.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;ct &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; V8&lt;span class="o"&gt;::&lt;/span&gt;v8&lt;span class="p"&gt;()&lt;/span&gt;
roundjs &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kr"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;x&lt;span class="p"&gt;,&lt;/span&gt; digits&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="kp"&gt;sapply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;x&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kr"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;y&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;ct&lt;span class="o"&gt;$&lt;/span&gt;&lt;span class="kp"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;paste0&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Number((&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kp"&gt;sprintf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;%.16f&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; y&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;).toFixed(&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; digits&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;))&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;))})&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The effect of the penalty can be prettily illustrated by a scatterplot of the
scores of two attributes.  Ties are separated, parting the cloud, slightly above
the line &lt;span class="math"&gt;\(y = x\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://nacnudus.github.io/crossprod/figure/radar-penalty-gap-1.svg" title="plot of chunk radar-penalty-gap" alt="plot of chunk radar-penalty-gap" width="960px" height="540px" /&gt;&lt;/p&gt;
&lt;p&gt;We can also de-penalise the scores to see the effect of the penalty on the
distribution.  Pre-penalty scores are distributed as you&amp;#8217;d expect, despite
slightly uneven weights.  Post-penalty scores are skewed to the right, but not
so much that you&amp;#8217;d notice in casual&amp;nbsp;use.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://nacnudus.github.io/crossprod/figure/radar-penalty-skew-1.svg" title="plot of chunk radar-penalty-skew" alt="plot of chunk radar-penalty-skew" width="960px" height="540px" /&gt;&lt;/p&gt;
&lt;p&gt;The magnitude of the penalty depends on the magnitude of the pre-penalty score
as well as its rank, introducing a tricky extra dimension to any visualisation.
Hexagonal bins work well, coloured according to frequency.  Penalties tend to be
largest for middling scores, where the rank tends to be poor enough to multiply
the penalty factor by a few times, but the magnitude of the score isn&amp;#8217;t small
enough to scale the penalty&amp;nbsp;down.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://nacnudus.github.io/crossprod/figure/radar-penalty-magnitude-1.svg" title="plot of chunk radar-penalty-magnitude" alt="plot of chunk radar-penalty-magnitude" width="960px" height="540px" /&gt;&lt;/p&gt;
&lt;h2 id="the-whole-point"&gt;The whole&amp;nbsp;point&lt;/h2&gt;
&lt;p&gt;It turns out that interpreting individual radars should be done more thoughtfully
than one might have expected,&amp;nbsp;because&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;5.2 = 7.0 for data-wrangling unicorns with perfect&amp;nbsp;answers.&lt;/li&gt;
&lt;li&gt;Scores aren&amp;#8217;t directly comparable between people, unless they&amp;#8217;re at the
  extremes where the penalties exaggerate&amp;nbsp;less.&lt;/li&gt;
&lt;li&gt;The correct answer to the statement &amp;#8220;On average, I spend at least 25% of my
  time manipulating data into analysis-ready formats&amp;#8221;, if you want a high &amp;#8216;Data
  Wrangler&amp;#8217; score, is &lt;em&gt;Strongly disagree&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And the &lt;a href="https://www.mango-solutions.com/radar/?fs=true&amp;amp;r=7.0,6.6,6.3,6.0,5.6,5.2"&gt;perfect score&lt;/a&gt;?&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;## Source: local data frame [6 x 2]
## 
##       attribute score
##           &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt;
## 1  Communicator   7.0
## 2      Modeller   6.6
## 3    Programmer   6.3
## 4  Technologist   6.0
## 5    Visualiser   5.6
## 6 Data Wrangler   5.2
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="Mango Solutions Data Science Radar: perfect score" src="figure/radar-perfect.png" /&gt;&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    var location_protocol = (false) ? 'https' : document.location.protocol;
    if (location_protocol !== 'http' &amp;&amp; location_protocol !== 'https') location_protocol = 'https:';
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Duncan Garmonsway</dc:creator><pubDate>Tue, 28 Jun 2016 00:00:00 +1200</pubDate><guid>tag:nacnudus.github.io,2016-06-28:crossprod/hacking-the-data-science-radar-with-data-science</guid><category>R</category><category>polls</category><category>Brexit</category></item><item><title>Brexit poll ofÂ polls</title><link>http://nacnudus.github.io/crossprod/brexit-poll-of-polls</link><description>&lt;p&gt;This post does the&amp;nbsp;following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Re-works the Financial Times poll-of-polls&amp;nbsp;graph&lt;/li&gt;
&lt;li&gt;Explores the relationship between sample size, polling method, and voting&amp;nbsp;intention.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="data"&gt;Data&lt;/h2&gt;
&lt;p&gt;I scraped the poll data from the &lt;a href="https://ig.ft.com/sites/brexit-polling"&gt;Financial Times poll of
polls&lt;/a&gt;.  The Financial Times made this
graph of&amp;nbsp;it:&lt;/p&gt;
&lt;p&gt;&lt;img alt="https://ig.ft.com/sites/brexit-polling" src="figure/brexit-ft-polls.png" /&gt;&lt;/p&gt;
&lt;p&gt;To check a later inference about sample sizes and online/telephone methods, I
also scraped polling data from the &lt;a href="http://www.bbc.co.uk/news/uk-politics-eu-referendum-36271589"&gt;&lt;span class="caps"&gt;BBC&lt;/span&gt; poll of
polls&lt;/a&gt; and used it
to augment the Financial Times data with the polling&amp;nbsp;method.  &lt;/p&gt;
&lt;p&gt;My analysis focusses on the Financial Times data, because the sample sizes are
provided, there is a longer time-series, and I didn&amp;#8217;t notice the &lt;span class="caps"&gt;BBC&lt;/span&gt;&amp;#8217;s version
until I&amp;#8217;d done most of the&amp;nbsp;work.&lt;/p&gt;
&lt;h2 id="reworking-the-graph"&gt;Reworking the&amp;nbsp;graph&lt;/h2&gt;
&lt;p&gt;The Financial Times graph emphasises the poll-of-polls statistic, and the
difference between online and telephone polls.  In my version, I want to
emphasise the outcomes (the majority in each poll), the margins of the
majorities, and the sample sizes.  I also present the full&amp;nbsp;series.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://nacnudus.github.io/crossprod/figure/brexit-timeseries1-1.svg" title="plot of chunk brexit-timeseries1" alt="plot of chunk brexit-timeseries1" width="960px" height="540px" /&gt;&lt;/p&gt;
&lt;p&gt;I would have included the poll-of-polls statistic on my graph, since the
Financial Times describes their method in a&amp;nbsp;footnote:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The &lt;span class="caps"&gt;FT&lt;/span&gt; poll of polls is calculated by taking the last seven polls from unique
pollsters up to a given date, removing the two polls with the highest and
lowest shares for &amp;#8216;remain&amp;#8217;, and calculating an adjusted average of the five
remaining polls, where the more recent polls are given a higher&amp;nbsp;weight&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Unfortunately, besides omitting the weights, and their tie-breaking policy,
their statistic has obviously been redesigned since the footnote was written,
because their current statistic for &amp;#8216;remain&amp;#8217; is higher than the second-highest
&amp;#8216;remain&amp;#8217; result in the last seven&amp;nbsp;polls.&lt;/p&gt;
&lt;p&gt;Here&amp;#8217;s that graph again, but this time beginning in September 2015 like the
Financial&amp;nbsp;Times.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://nacnudus.github.io/crossprod/figure/brexit-timeseries2-1.svg" title="plot of chunk brexit-timeseries2" alt="plot of chunk brexit-timeseries2" width="960px" height="540px" /&gt;&lt;/p&gt;
&lt;p&gt;Something worth noticing is that the &amp;#8216;leave&amp;#8217; majorities are mostly large
samples.  Comparing this graph with the one by the Financial Times, sample size
seems to be a proxy for telephone (small) vs online (large) polling methods.
Let&amp;#8217;s&amp;nbsp;check.&lt;/p&gt;
&lt;p&gt;Although the Financial Times graph distinguishes between online/telephone
methods, that information isn&amp;#8217;t included in the table, despite its obvious
&lt;a href="https://yougov.co.uk/news/2016/02/23/commentary-what-explains-difference-between-phone-"&gt;importance&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Thereâs a big difference between the online and telephone polls on the &lt;span class="caps"&gt;EU&lt;/span&gt;
referendum â with online polls showing the sides neck-and neck and telephone
polls showing about a 15% gap in favour of âremainâ.&amp;nbsp;Why?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Fortunately, for most polls in the last six months, data from the &lt;a href="http://www.bbc.co.uk/news/uk-politics-eu-referendum-36271589"&gt;&lt;span class="caps"&gt;BBC&lt;/span&gt;&amp;#8217;s poll of
polls&lt;/a&gt; can augment
the Financial Times data with online/telephone information.  As the following
frequency table shows, in nearly all matched polls, large samples correspond
with an online method.  So while large samples appear to favour &amp;#8216;leave&amp;#8217;, it may
simply be that online polls&amp;nbsp;do.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;##         
##          online phone &amp;lt;NA&amp;gt; Sum
##   &amp;lt; 1400      8    18   35  61
##   â¥ 1400     67     0  114 181
##   &amp;lt;NA&amp;gt;       10     5    0  15
##   Sum        85    23  149 257
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;However, telephone polls do not necessarily favour either side.  Comparing the
frequencies of outcomes with first methods and then sample sizes, the
association between small sample sizes and a &amp;#8216;remain&amp;#8217; outcome appears to be much
stronger than between &amp;#8216;online&amp;#8217; and &amp;#8216;remain&amp;#8217; or &amp;#8216;phone&amp;#8217; and &amp;#8216;remain&amp;#8217;.  Perhaps
this is why the financial markets apparently regard telephone polls as more
reliable, despite the smaller sample&amp;nbsp;sizes.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;##         
##          leave remain &amp;lt;NA&amp;gt; Sum
##   online    26     49   10  85
##   phone      1     17    5  23
##   &amp;lt;NA&amp;gt;      52     97    0 149
##   Sum       79    163   15 257
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;##         
##          leave remain &amp;lt;NA&amp;gt; Sum
##   &amp;lt; 1400    15     46    0  61
##   â¥ 1400    64    117    0 181
##   &amp;lt;NA&amp;gt;       0      0   15  15
##   Sum       79    163   15 257
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="outcome-by-sample-size-polling-method"&gt;Outcome by sample size / polling&amp;nbsp;method&lt;/h2&gt;
&lt;p&gt;I already noted that &amp;#8216;leave&amp;#8217; majorities tend to come from large-sample/online
polls.  The next graph makes this more&amp;nbsp;obvious.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://nacnudus.github.io/crossprod/figure/brexit-outcome-by-sample-size-1.svg" title="plot of chunk brexit-outcome-by-sample-size" alt="plot of chunk brexit-outcome-by-sample-size" width="960px" height="540px" /&gt;&lt;/p&gt;
&lt;h2 id="justification-of-largesmall-threshold"&gt;Justification of large/small&amp;nbsp;threshold&lt;/h2&gt;
&lt;p&gt;But how did I choose 1400 as the boundary between small and large samples?  It&amp;#8217;s
because of the following visualisations,  Polls with samples smaller than 1400
just seem to behave differently. Perhaps small samples don&amp;#8217;t find the &amp;#8216;leave&amp;#8217;
voters, or perhaps they &lt;em&gt;do&lt;/em&gt; find the &amp;#8216;remain&amp;#8217;&amp;nbsp;ones.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://nacnudus.github.io/crossprod/figure/brexit-remain-by-sample-size-1.svg" title="plot of chunk brexit-remain-by-sample-size" alt="plot of chunk brexit-remain-by-sample-size" width="960px" height="540px" /&gt;&lt;/p&gt;
&lt;p&gt;Smaller samples also don&amp;#8217;t find the undecided people (this is not quite as
convincing as the graph&amp;nbsp;above).&lt;/p&gt;
&lt;p&gt;&lt;img src="http://nacnudus.github.io/crossprod/figure/brexit-undecided-by-sample-size-1.svg" title="plot of chunk brexit-undecided-by-sample-size" alt="plot of chunk brexit-undecided-by-sample-size" width="960px" height="540px" /&gt;&lt;/p&gt;
&lt;p&gt;Checking this against the method data from the &lt;span class="caps"&gt;BBC&lt;/span&gt;, I&amp;#8217;m arguably on the right
track.  It would obviously be best to know the method as well as the sample
size, but since I&amp;#8217;m using the Financial Times data, and since I don&amp;#8217;t have the
method of so many of those polls (grey points below), I have focussed on sample
size&amp;nbsp;instead.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://nacnudus.github.io/crossprod/figure/brexit-method-vs-sample-size-1.svg" title="plot of chunk brexit-method-vs-sample-size" alt="plot of chunk brexit-method-vs-sample-size" width="960px" height="540px" /&gt;&lt;img src="http://nacnudus.github.io/crossprod/figure/brexit-method-vs-sample-size-2.svg" title="plot of chunk brexit-method-vs-sample-size" alt="plot of chunk brexit-method-vs-sample-size" width="960px" height="540px" /&gt;&lt;/p&gt;
&lt;h2 id="indecision-favours-a-leave-outcome-part-i-graph"&gt;Indecision favours a &amp;#8216;leave&amp;#8217; outcome: Part I &amp;#8212;&amp;nbsp;graph&lt;/h2&gt;
&lt;p&gt;Here I can use stats, the only stats I&amp;#8217;ve ever been taught (the really
out-of-date stuff), to explore whether undecided voters will favour the status
quo.  (What is my status quo, anyway &amp;#8212; that we&amp;#8217;re in Europe now, or that I&amp;#8217;ve
always wanted to&amp;nbsp;leave?)&lt;/p&gt;
&lt;p&gt;Here&amp;#8217;s the association between indecision and the &amp;#8216;remain&amp;#8217;&amp;nbsp;vote.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://nacnudus.github.io/crossprod/figure/brexit-indecision-by-remain-1.svg" title="plot of chunk brexit-indecision-by-remain" alt="plot of chunk brexit-indecision-by-remain" width="960px" height="540px" /&gt;&lt;/p&gt;
&lt;h2 id="intermission-obvious-glitch"&gt;Intermission (obvious&amp;nbsp;glitch)&lt;/h2&gt;
&lt;p&gt;A few &amp;#8216;remain&amp;#8217; majorities are below the &amp;#8216;win&amp;#8217; threshold in the graph above
(green points below the dotted line).  That could be because of missing
&amp;#8220;won&amp;#8217;t vote&amp;#8221; information.  See YouGov&amp;#8217;s
&lt;a href="https://yougov.co.uk/news/2016/02/23/commentary-what-explains-difference-between-phone-"&gt;explanation&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Telephone polls ask their respondents âHow will you vote in the
referendum?â People are assumed to have an opinion, and 90% of them give 
one. By contrast, online polls present people with options: remain, leave,
wonât vote, donât know â there is less assumption of an opinion, and 20% or
more donât offer&amp;nbsp;one.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;A few polls total much less than 100%, probably for the same reason, but it
isn&amp;#8217;t a problem in most&amp;nbsp;cases.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://nacnudus.github.io/crossprod/figure/brexit-totals-1.svg" title="plot of chunk brexit-totals" alt="plot of chunk brexit-totals" width="960px" height="540px" /&gt;&lt;/p&gt;
&lt;h2 id="indecision-favours-a-leave-outcome-part-ii-stats"&gt;Indecision favours a &amp;#8216;leave&amp;#8217; outcome: Part &lt;span class="caps"&gt;II&lt;/span&gt; &amp;#8212;&amp;nbsp;stats&lt;/h2&gt;
&lt;p&gt;We&amp;#8217;ve already seen the non-linearity of sample size vs everything, so I build
two models, first for large samples, then for small&amp;nbsp;ones.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;## 
## Call:
## lm(formula = remain ~ undecided, data = master_ft %&amp;gt;% filter(sample_size == 
##     &amp;quot;â¥ 1400&amp;quot;))
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.152068 -0.015749  0.004864  0.024251  0.100785 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)  0.49431    0.01027  48.130  &amp;lt; 2e-16 ***
## undecided   -0.46932    0.05599  -8.383 1.49e-14 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 0.03745 on 179 degrees of freedom
## Multiple R-squared:  0.2819, Adjusted R-squared:  0.2779 
## F-statistic: 70.27 on 1 and 179 DF,  p-value: 1.487e-14
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The coefficient of &amp;#8216;undecided&amp;#8217; is nearly -0.5, suggesting that undecided
large-sample voters about as likely to vote either way (lines almost parallel in
the graph below).  But as proportion of undecided voters reduces, at what point
does the &amp;#8216;remain&amp;#8217; outcome start to benefit?  (this analysis will be more
meaningful for small samples, in just a&amp;nbsp;moment).&lt;/p&gt;
&lt;p&gt;There are two linear functions: the fitted model, and the threshold of a
majority (depending on the proportion of voters who are undecided).  Not only
can we plot these functions (and base R is simplest here), but we can solve
them for the fulcrum, which turns out to be about 19%.  If the proportion of
voters who are undecided is below 19%, then outcome is likely to be&amp;nbsp;&amp;#8216;remain&amp;#8217;.&lt;/p&gt;
&lt;p&gt;I exhibit the R code here, for anyone interested in plotting functions and
solving&amp;nbsp;them.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;remain &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kr"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;x&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;coef&lt;span class="p"&gt;(&lt;/span&gt;lm_large&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; x &lt;span class="o"&gt;+&lt;/span&gt; coef&lt;span class="p"&gt;(&lt;/span&gt;lm_large&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]}&lt;/span&gt;
majority &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kr"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;x&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{(&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; x&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
plot&lt;span class="p"&gt;(&lt;/span&gt;remain&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; xlab &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;undecided&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; col &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;blue&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
plot&lt;span class="p"&gt;(&lt;/span&gt;majority&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; col &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;brown&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; add &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src="http://nacnudus.github.io/crossprod/figure/brexit-fulcrum-large-1.svg" title="plot of chunk brexit-fulcrum-large" alt="plot of chunk brexit-fulcrum-large" width="960px" height="540px" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;fulcrum &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kr"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;x&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;remain&lt;span class="p"&gt;(&lt;/span&gt;x&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; majority&lt;span class="p"&gt;(&lt;/span&gt;x&lt;span class="p"&gt;)}&lt;/span&gt;
uniroot&lt;span class="p"&gt;(&lt;/span&gt;fulcrum&lt;span class="p"&gt;,&lt;/span&gt; interval &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;$&lt;/span&gt;root
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;## [1] 0.1855785
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;master_ft &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; filter&lt;span class="p"&gt;(&lt;/span&gt;sample_size &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;â¥ 1400&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; undecided &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="m"&gt;0.1855785&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; &lt;span class="kp"&gt;nrow&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;## [1] 89
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Since &amp;#8220;small&amp;#8221; may be a proxy for &amp;#8220;online&amp;#8221;, let&amp;#8217;s model that,&amp;nbsp;too.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;## 
## Call:
## lm(formula = remain ~ undecided, data = master_ft %&amp;gt;% filter(sample_size == 
##     &amp;quot;&amp;lt; 1400&amp;quot;))
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.147178 -0.028871  0.004515  0.035027  0.178669 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)  0.57795    0.01514  38.177  &amp;lt; 2e-16 ***
## undecided   -0.80511    0.09922  -8.114 3.51e-11 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 0.05248 on 59 degrees of freedom
## Multiple R-squared:  0.5274, Adjusted R-squared:  0.5194 
## F-statistic: 65.84 on 1 and 59 DF,  p-value: 3.507e-11
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This time, the coefficient of undecided is about -0.8, suggesting that
undecided small-sample voters are more likely to vote to remain.  The fulrum,
now much more meaningful than above, given the coefficient, is at about 26%,
with a caveat that there are only five observations above&amp;nbsp;26%.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;remain &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kr"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;x&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;coef&lt;span class="p"&gt;(&lt;/span&gt;lm_small&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; x &lt;span class="o"&gt;+&lt;/span&gt; coef&lt;span class="p"&gt;(&lt;/span&gt;lm_small&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]}&lt;/span&gt;
majority &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kr"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;x&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{(&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; x&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
plot&lt;span class="p"&gt;(&lt;/span&gt;remain&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; xlab &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;undecided&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; col &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;blue&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
plot&lt;span class="p"&gt;(&lt;/span&gt;majority&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; col &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;brown&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; add &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src="http://nacnudus.github.io/crossprod/figure/brexit-fulcrum-small-1.svg" title="plot of chunk brexit-fulcrum-small" alt="plot of chunk brexit-fulcrum-small" width="960px" height="540px" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;fulcrum &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kr"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;x&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;remain&lt;span class="p"&gt;(&lt;/span&gt;x&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; majority&lt;span class="p"&gt;(&lt;/span&gt;x&lt;span class="p"&gt;)}&lt;/span&gt;
uniroot&lt;span class="p"&gt;(&lt;/span&gt;fulcrum&lt;span class="p"&gt;,&lt;/span&gt; interval &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;$&lt;/span&gt;root
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;## [1] 0.2554619
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;master_ft &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; filter&lt;span class="p"&gt;(&lt;/span&gt;sample_size &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&amp;lt; 1400&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; undecided &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="m"&gt;0.255461&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; &lt;span class="kp"&gt;nrow&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;## [1] 5
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="zero-undecided-voters"&gt;Zero undecided&amp;nbsp;voters&lt;/h2&gt;
&lt;p&gt;Finally, what about the five zero-undecided polls (the five points along the
bottom of the timeseries)?  It turns out that those polls were all conducted by
the &lt;span class="caps"&gt;ORB&lt;/span&gt; company, and they&amp;#8217;re also the large-sample polls by &lt;span class="caps"&gt;ORB&lt;/span&gt;.  They aren&amp;#8217;t
included in the &lt;span class="caps"&gt;BBC&lt;/span&gt; data, so we can&amp;#8217;t tell whether or not they are online polls.
Make of them what you&amp;nbsp;will.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;## Source: local data frame [5 x 11]
## 
##   remain leave undecided       date pollster sample sample_size majority
##    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;date&amp;gt;    &amp;lt;chr&amp;gt;  &amp;lt;dbl&amp;gt;       &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;
## 1   0.50  0.50         0 2016-04-29      ORB   2000      â¥ 1400   remain
## 2   0.51  0.49         0 2016-03-28      ORB   2002      â¥ 1400   remain
## 3   0.48  0.52         0 2015-11-19      ORB   2067      â¥ 1400    leave
## 4   0.53  0.47         0 2015-10-25      ORB   2015      â¥ 1400   remain
## 5   0.55  0.45         0 2015-09-06      ORB   2044      â¥ 1400   remain
## Variables not shown: max_percent &amp;lt;dbl&amp;gt;, min_percent &amp;lt;dbl&amp;gt;, method &amp;lt;chr&amp;gt;.
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img src="http://nacnudus.github.io/crossprod/figure/brexit-zero-undecided-1.svg" title="plot of chunk brexit-zero-undecided" alt="plot of chunk brexit-zero-undecided" width="960px" height="540px" /&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Duncan Garmonsway</dc:creator><pubDate>Mon, 13 Jun 2016 00:00:00 +1200</pubDate><guid>tag:nacnudus.github.io,2016-06-13:crossprod/brexit-poll-of-polls</guid><category>R</category><category>polls</category><category>Brexit</category></item></channel></rss>